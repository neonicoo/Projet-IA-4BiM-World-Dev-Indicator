{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet IA - 4BiM - 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Auteurs : Aurélie Fischer et Nicolas Mendiboure \n",
    "#### Enseignants : Sergio Peignier et Chistophe Rigotti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy\n",
    "import math\n",
    "import sklearn\n",
    "import pandas as pds\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.cluster.hierarchy as sch\n",
    "\n",
    "#import sergio_peignier as sp\n",
    "#import chistophe_rigotti as cr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Lecture des données:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df = pds.read_csv(\"./datas/Data-IA-World-Development-Indicator.txt\", sep=\"\\t\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparse_df.head()\n",
    "#sparse_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quelques statistiques :\n",
    "sparse_df.describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Création des classes (continents) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry_convert as pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code = sparse_df[[\"Country Name\", \"Country Code\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code_np = country_code[\"Country Code\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_to_continent(country_code):\n",
    "    res = []\n",
    "    for code3 in country_code :\n",
    "        if (code3 == \"CHI\"):\n",
    "            code2 = \"GB\"\n",
    "        elif (code3 == \"XKX\"):\n",
    "            code2 = \"XK\"\n",
    "        else:\n",
    "            code2 = pc.country_alpha3_to_country_alpha2(code3)\n",
    "            \n",
    "        \n",
    "        if (code2 == \"TL\"):\n",
    "            country_continent_code = \"AS\"\n",
    "        elif (code2 == \"SX\"):\n",
    "            country_continent_code = \"SA\"\n",
    "        else:\n",
    "            country_continent_code = pc.country_alpha2_to_continent_code(code2)\n",
    "        country_continent_name = pc.convert_continent_code_to_continent_name(country_continent_code)\n",
    "        res.append(country_continent_name)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continents = country_to_continent(country_code_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df[\"Continents\"] = continents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Selection et filtrage des données :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Selection des attributs (colonnes) :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premiers apperçus des données du jeu (décommenter pour afficher) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction qui supprime une colonne (attribut) si le nb de NaN >= limit\n",
    "\n",
    "def delete_NaN_col(df, limit):\n",
    "    NaN_col = df.isna().sum()\n",
    "    tmp = df.copy(deep=True) #temporary df\n",
    "    \n",
    "    for i in range(df.shape[1]):\n",
    "        if NaN_col[i] >= limit:\n",
    "            df = df.drop(columns = tmp.columns[i])\n",
    "            \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df2 = delete_NaN_col(sparse_df, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enlèvre les colonnes 'Time' et 'Time Code' qui ne nous interessent pas ici\n",
    "def remove_useless_col(df):\n",
    "    df = df.drop(columns = [\"Time\", \"Time Code\", \"Country Code\"])\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df2 = remove_useless_col(sparse_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Selection des objets (lignes) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df2.isna().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction qui supprime une ligne (object) si le nb de NaN >= limit\n",
    "\n",
    "def delete_NaN_row(df, limit):\n",
    "    NaN_row = df.isna().sum(axis=1)\n",
    "    tmp = df.copy(deep=True) #temporary df\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        if NaN_row[i] >= limit:\n",
    "            df = df.drop([i], axis = 0)\n",
    "            \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df3 = delete_NaN_row(sparse_df2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On remplace les indexes des ligne {0, 1, 2, ..n} par les noms de pays\n",
    "#Puis on supprime la colonne \"Countru Name\" pour n'avoir plus que des valeurs numériques\n",
    "sparse_df3.index = sparse_df3['Country Name']\n",
    "sparse_df3 = sparse_df3.drop(columns = ['Country Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Études des correlations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = sparse_df3.corr()\n",
    "corr_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représentation graphique des correlations\n",
    "plt.figure(figsize= (15, 12))\n",
    "sns.heatmap(corr_df,annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(corr_df,\n",
    "               figsize= (16, 12),\n",
    "               annot=True,\n",
    "               dendrogram_ratio=(0.1, 0.2),\n",
    "               row_cluster=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_corr(df, limit):\n",
    "    #On construit notre matrice de correlation en valeur absolue\n",
    "    corr_matrix = df.corr().abs()\n",
    "    \n",
    "    #Triangle supérieur de la matrice de corrélation : \n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > limit)]\n",
    "    df = df.drop(df[to_drop], axis=1)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = delete_corr(sparse_df3, 0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (15, 12))\n",
    "sns.heatmap(df.corr().abs(), annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On ne sait pas vraiment à quoi correspond cet attribut\n",
    "#De plus il faudrait normaliser ses valeurs, sauf que nous ne connaissons aucun référentiel pour faire cela\n",
    "df = df.drop(columns=[\"Net domestic credit (current LCU) [FM.AST.DOMS.CN]\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On renomme les labels des colonnes pour plus de fluidité\n",
    "df = df.rename(columns={\"Access to clean fuels and technologies for cooking (% of population) [EG.CFT.ACCS.ZS]\" : \"Clean fuels and technologies for cooking acces (% pop)\"})\n",
    "df = df.rename(columns={\"Aquaculture production (metric tons) [ER.FSH.AQUA.MT]\" : \"Aquaculture prod (metric tons)\"})\n",
    "df = df.rename(columns={\"Compulsory education, duration (years) [SE.COM.DURS]\" : \"Compulsory education duration (years)\"})\n",
    "df = df.rename(columns={\"Death rate, crude (per 1,000 people) [SP.DYN.CDRT.IN]\" : \"Death rate (per 10e3 )\"})\n",
    "df = df.rename(columns={\"Incidence of tuberculosis (per 10e5 people) [SH.TBS.INCD]\" : \"Incidence of tuberculosis (per 100 000)\"})\n",
    "df = df.rename(columns={\"Number of infant deaths [SH.DTH.IMRT]\" : \"Number of infant deaths\"})\n",
    "df = df.rename(columns={\"Preprimary education, duration (years) [SE.PRE.DURS]\" : \"Preprimary education duration (years)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Normalisation relative (aux surfaces et poplations par pays) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_country(df, df_ref):\n",
    "    tmp = df.copy(deep = True)\n",
    "    for i, country in  enumerate( tmp[\"Country Name\"]):\n",
    "        if country not in df_ref.index.values:\n",
    "            df = df.drop(tmp.index[i], axis = 0)\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_size = pds.read_csv(\"./datas/Popula-schtroumpf/Population-size-per-country.txt\", sep=\"\\t\", header=0)\n",
    "population_size = remove_useless_col(population_size)\n",
    "population_size = delete_NaN_row(population_size, 1)\n",
    "population_size = remove_country(population_size, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surfaces = pds.read_csv(\"./datas/Surfa-schtroumpf/Country-surfaces.txt\", sep=\"\\t\", header=0)\n",
    "surfaces = remove_useless_col(surfaces)\n",
    "surfaces = delete_NaN_row(surfaces, 1)\n",
    "surfaces = remove_country(surfaces, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(population_size) == len(df), len(surfaces)== len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy(deep = True)\n",
    "print(\"Avant :\", \"\\n\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.iloc[:, 1] =  df2.iloc[:, 1].values/surfaces.iloc[:, 1].values\n",
    "df2.iloc[:, 5] =  df2.iloc[:, 5].values/population_size.iloc[:, 1].values\n",
    "print(\"Après :\", \"\\n\")\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Normalisation par centrage - réduction :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "    X = \\frac{X - \\mu}{\\sigma}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "sns.boxplot(data = df2)\n",
    "plt.show()\n",
    "\n",
    "#On voit que les ordres de grandeur de nos données ainsi que leur variances ne sont pas du tout homogènes.\n",
    "#On va donc les normaliser (centrer - réduire) pour corriger ce défaut  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui centre et réduit une colonne de données pour les normaliser\n",
    "def normalizer (data):\n",
    "    # Quelques statistiques :\n",
    "    mean = np.mean(data)\n",
    "    var = np.var(data)\n",
    "    sd = math.sqrt(var)\n",
    "    \n",
    "    norm = []\n",
    "    for x in data:\n",
    "        norm.append((x-mean)/sd)\n",
    "    \n",
    "    return (norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_whole_df (df):\n",
    "    normed_df = df.copy(deep = True)\n",
    "    for i in df.columns:\n",
    "        normed_df[i] = normalizer(df[i])\n",
    "        \n",
    "    return (normed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_df = norm_whole_df(df2.drop(columns = \"Continents\" ))\n",
    "normed_df[\"Continents\"] = df2[\"Continents\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,15))\n",
    "sns.boxplot(data = normed_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_outliers_row(df, limit):\n",
    "    z_scores = stats.zscore(df.drop(columns = \"Continents\" )) #calcule le z-score de df\n",
    "    abs_z_scores = np.abs(z_scores) # on passe en valeurs absolues\n",
    "    filtered_outliers = (abs_z_scores < limit).all(axis=1) # on ne garde que les lignes avec des valeurs > limit\n",
    "    new_df = df[filtered_outliers] #nouveau df\n",
    "    return (new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = search_outliers_row(normed_df, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,15))\n",
    "sns.boxplot(data = df3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pairplot après standardisation\n",
    "sns.pairplot(data=df3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On refait des statistiques basiques sur notre nouveau jeu de données df3. On voit bie nque notre moyenne est centrée sur 0 et que notre écart type varie autour de 1 pour chaque attribut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stats = df3.describe()\n",
    "df_stats = df_stats.drop('count',axis=0)\n",
    "sns.heatmap(df_stats,annot=True,cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Clustering :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 K-means "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 Création des clusters :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.drop(columns = \"Continents\" )\n",
    "classes = df3.Continents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utilisé le jeu de données fraichement filtré et normalisé df2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un object KMeans :\n",
    "km = KMeans(n_clusters=4, init='k-means++',n_init=10, random_state=50, max_iter=300,)\n",
    "km.fit(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_clusters = km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On stocke les centroides obtenus :\n",
    "centroids = km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = km.predict(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using matplotlib.pyplot instead of seaborn.scatterplot to display the clusters.\n",
    "plt.scatter(df4[\"Clean fuels and technologies for cooking acces (% pop)\"], df4[\"Compulsory education duration (years)\"], c=km_clusters)\n",
    "plt.title('Data in Space', fontsize=14)\n",
    "plt.xlabel(\"Clean fuels and technologies for cooking acces (% pop)\",fontsize=14)\n",
    "plt.ylabel(\"Compulsory education duration (years)\",fontsize=14 )\n",
    "plt.scatter(centroids[:, 0], centroids[:, 2], c='red',s=150, alpha=0.4)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 Mesures sur nos kmeans :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "Counter(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) SSE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSE=km.inertia_\n",
    "print(SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Courbe de la SSE en fonction du nombre de clusters\n",
    "SSE_liste=[]\n",
    "for i in range(2,10):\n",
    "    km2=KMeans(n_clusters=i, init='k-means++',  n_init=1, random_state=50, max_iter=1000).fit(df4)\n",
    "    SSE_liste.append(km2.inertia_)\n",
    "    \n",
    "#print(SSE_liste)\n",
    "\n",
    "SSE_liste_random=[]\n",
    "x=[]\n",
    "for i in range(2,10):\n",
    "    km3=KMeans(n_clusters=i, init='random',  n_init=1, random_state=50, max_iter=1000).fit(df4)\n",
    "    SSE_liste_random.append(km3.inertia_)\n",
    "    x.append(i)\n",
    "    \n",
    "#print(SSE_liste_random)\n",
    "plt.figure(figsize = (14, 10))\n",
    "plt.plot(x, SSE_liste,label=\"k-means++\")\n",
    "plt.plot(x, SSE_liste_random,label=\"Random\")\n",
    "plt.xlabel(\"Nombre de clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table de contingence avec les différents clusters vs les classes (ici continents) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_crosstab = pds.crosstab(km_clusters,classes)\n",
    "sns.heatmap(km_crosstab, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Mesures d'entropie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropie des clusters (c) comparés aux différentes classes (j):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$-\\sum{p(j|c) \\times log(p(j|c)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(j|c)$ est la fréquence d'apparition de la classe j dans le cluster c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = km_crosstab.values/km_crosstab.values.sum(axis=1, keepdims=True) # divide each element of a row by the sum of the row\n",
    "entropy = [stats.entropy(row, base=2) for row in proba]\n",
    "print(\"entropy of each cluster: \", entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Mesure de pureté :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour calculer la pureté, chaque cluster est attribué à la classe qui est la plus fréquente dans ce cluster, puis la précision de cette attribution est mesurée en comptant le nombre d'éléments correctement attribués. Il s'agit donc de mesurer la précision d'un cluster à ne contenir les objets que d'une seule classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En réalité il s'agit d'une terminologie dérivant de l'entropie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$purete = \\sum_{j=1}^{K} \\frac{m_c}{m} \\times purete(c)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $purete(c) = max(p(j,c))$;\n",
    "- $p(j,c)$ est la probabilité qu'un membre du cluster $c$ appartienne à la classe $j$;\n",
    "- $m_c$ est la taille du cluster $c$;\n",
    "- $m$ est la taille totale du nombre d'éléments (points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity_score(classes, predictions):\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(classes, predictions)\n",
    "    return ( np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purity_score(classes, km_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>Remarque :</ins> Une grande pureté est facile à atteindre lorsque le nombre de clusters formés devient important. En particulier, la pureté tend vers $1$ si le nombre de cluster tend à être égale aux nombre de points. Ainsi, nous ne pouvons pas utiliser la pureté pour faire un compromis entre la qualité du regroupement et le nombre de regroupements.\n",
    "\n",
    "Une mesure qui nous permet de faire ce compromis est l'information mutuelle normalisée ou INM : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Information mutuelle normalisée (IMN) :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$IMN(j,c) = \\frac{2 \\times I(j, c)}{E(j) + E(c)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $j$ = label de la classe ;\n",
    "- $c$ = label du cluster ;\n",
    "- $E()$ = entropie ;\n",
    "- $I(j, c)$ = information mutuelle entre j et c. $I(j, c) = E(j) - E(j|c)$, où $E(j|c)$ désigne une entropie conditionnelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.normalized_mutual_info_score(classes, km_clusters, average_method='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Coefficient de silhouette :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le coefficient de silhouette pour un  point correspond à la différence entre sa distance moyenne avec les points du même cluster que lui (**cohésion**) et la distance moyenne avec les points des autres clusters voisins (**séparation**). Il est compris en $-1$ et $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Si on a une différence négative, le point est en moyenne plus proche du groupe voisin que du sien ;\n",
    " - Si on a une différence positive, le point est en moyenne plus proche de son groupe que du groupe voisin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Silh = metrics.silhouette_score(df4.values, \n",
    "                         km_clusters, \n",
    "                         metric='euclidean', \n",
    "                         sample_size=None) \n",
    "print(\"Coefficient de silhouette pour nos 3 clusters : \",Silh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import SilhouetteVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec le code suivant nous pouvons observer les silhouettes de chaque cluster, pour un nombre total de  2, 3, 4, 5, 6 et 7 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 2, figsize=(15,10))\n",
    "for i in [2, 3, 4, 5, 6, 7]:\n",
    "    \n",
    "    km_simu = KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=100, random_state=42)\n",
    "    q, mod = divmod(i, 2) # permet d'attribuer les axes pour les subplots \n",
    "    \n",
    "    visualizer = SilhouetteVisualizer(km_simu, colors='yellowbrick', ax=ax[q-1][mod])\n",
    "    visualizer.fit(df4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 Stabilité de la convergence de nos k-means :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La convergence d'un algorithme K-Means peut être vue comme étant la stabilisation des centroids des clusters (les centroids ne bougent plus lors des itérations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a) Calcul de la stabilité pour la convergence de notre K-means :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_silhouette_coef = []\n",
    "sse_list = []\n",
    "k = 6\n",
    "for i in range(600):\n",
    "    km = KMeans(n_clusters=k, init='random', n_init=1)\n",
    "    km.fit(df4)\n",
    "    labels = km.predict(df4)\n",
    "    sse_list.append(np.sqrt(km.inertia_))\n",
    "    avg_silhouette_coef.append(metrics.silhouette_score(df4, labels,metric='euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "plt.subplot(2,2,1)\n",
    "plt.hist(sse_list, edgecolor = \"black\")\n",
    "plt.title(\"SSE\", fontsize = 18)\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.hist(avg_silhouette_coef, edgecolor = \"black\")\n",
    "plt.title(\"Average silhouette coeff\", fontsize = 18)\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.boxplot(sse_list)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.boxplot(avg_silhouette_coef)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Même chose mais avec un nombre d'executions interne plus grand :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici nous allons effectuer la même opération qu'au dessus en changeant la valeur du *n_init* par une valeur plus élevée. Pour rappel le paramètre *n_init* représente le nombre de fois où l'algorithme du k-means sera exécuté avec différentes graines pour les centroïdes. Le meilleur résltat en terme d'inertie sera retenue parmi tous les *n_init*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_silhouette_coef = []\n",
    "sse_list = []\n",
    "k = 6\n",
    "for i in range(600):\n",
    "    km = KMeans(n_clusters=k, init='random', n_init = 30)\n",
    "    km.fit(df4)\n",
    "    labels = km.predict(df4)\n",
    "    sse_list.append(np.sqrt(km.inertia_))\n",
    "    avg_silhouette_coef.append(metrics.silhouette_score(df4, labels,metric='euclidean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.hist(sse_list, color='coral', edgecolor = \"black\")\n",
    "plt.title(\"SSE\", fontsize = 18)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.hist(avg_silhouette_coef, color = 'coral', edgecolor = \"black\")\n",
    "plt.title(\"Average silhouette coeff\", fontsize = 18)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Evaluation de la stabilité de convergence un nombre de clusters différents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stability(km,df,iterations=100):\n",
    "    avg_silhouette_coef = []\n",
    "    sse_list = []\n",
    "    for i in range(500):\n",
    "        km.fit(df)\n",
    "        labels = km.predict(df)\n",
    "        avg_silhouette_coef.append(metrics.silhouette_score(df, labels,metric='euclidean'))\n",
    "    avg_silhouette_coef = np.asarray(avg_silhouette_coef)\n",
    "    return(avg_silhouette_coef.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stability = []\n",
    "Ks = range(2,12)\n",
    "for k in Ks:\n",
    "    km = KMeans(n_clusters=k,init='random',n_init=5)\n",
    "    stability.append(compute_stability(km,df4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Ks,stability,\"o-\")\n",
    "plt.xlabel(\"number of clusters \",fontsize=20)\n",
    "plt.ylabel(\"Avg. Silhouette Coef\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Le nombre de clusters pour une stabilité optimale est : \", int(stability.index(max(stability))) + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Hierachical clustering :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Méthode : \"complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_complete = sch.linkage(df4, method = 'complete', metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 40))\n",
    "dendro = sch.dendrogram(z_complete, \n",
    "                        orientation='right', \n",
    "                        leaf_rotation=0, \n",
    "                        leaf_font_size=14,\n",
    "                        labels = df4.index)\n",
    "plt.title(\"Dendrogram with complete methode\")\n",
    "plt.ylabel(\"Countries\")\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Méthode : \"single\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_single = sch.linkage(df4, method = 'single', metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_single.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 40))\n",
    "dendro = sch.dendrogram(z_single, \n",
    "                        orientation='right', \n",
    "                        leaf_rotation=0, \n",
    "                        leaf_font_size=14,\n",
    "                        labels = df4.index)\n",
    "plt.title(\"Dendrogram with single methode\")\n",
    "plt.ylabel(\"Countries\")\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd derivative of the distances\n",
    "\n",
    "acceleration_complete = np.diff(z_complete[:,2], 2)\n",
    "acceleration_single = np.diff(z_single[:,2], 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(32, 18))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.plot(z_single[:, 2], 'o-', color = \"blue\")\n",
    "plt.plot(z_complete[:, 2], 'o-', color = \"orange\")\n",
    "plt.legend([\"single\",\"complete\"])\n",
    "plt.ylabel(\"Hauteur\", fontsize = 22)\n",
    "plt.xlabel(\"Pays par ordre croissant\", fontsize = 22)\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(z_complete[:, 2], 'o-', color = \"orange\")\n",
    "plt.plot(acceleration_complete, 'o-', color='green')\n",
    "plt.ylabel(\"Hauteur\", fontsize = 22)\n",
    "plt.legend([\"complete\",\"dérivée seconde de complete\"], fontsize = 22)\n",
    "plt.xlabel(\"Pays par ordre croissant\", fontsize = 22)\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(z_single[:, 2], 'o-', color = \"blue\")\n",
    "plt.plot(acceleration_complete, 'o-', color='green')\n",
    "plt.legend([\"single\",\"dérivée seconde de signle\"], fontsize = 22)\n",
    "plt.ylabel(\"Hauteur\", fontsize = 22)\n",
    "plt.xlabel(\"Pays par ordre croissant\", fontsize = 22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 DB scan :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une méthode pour estimer le meilleur paramètre **eps** pour notre DBscan serait de calculer la distance de chaque point par rapport à son voisin le plus proche en utilisant les **NearestNeighbors**. Le point lui-même est inclus dans n_neighbors. Nous obtenons ensuite deux tableaux:\n",
    "\n",
    "- Un qui contient la distance aux points n_neighbors les plus proches ;\n",
    "- Le deuxième contient l'indice pour chacun de ces points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neigh = NearestNeighbors(n_neighbors=2)\n",
    "nbrs = neigh.fit(df4.values)\n",
    "distances, indices = nbrs.kneighbors(df4.values)\n",
    "distances = np.sort(distances, axis=0)\n",
    "distances = distances[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons ordonner nos résultats et les afficher dans un plot semblable à ceux déja vu pour des les SSE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "ax = plt.subplot(111)\n",
    "eps_curve = ax.plot(distances, 'o-', color='b')\n",
    "plt.ylabel(\"eps\", fontsize = 18)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin la valeur optimale pour le paramètre **eps** trouve à la courbure maximale de la courbe, lu en ordonnée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour le déterminer nous allons importer la librairie Kneed qui va utiliser la méthode \"des genoux\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kneed import KneeLocator\n",
    "points = eps_curve[0].get_data() # on récupère les points de la courbe (x et y)\n",
    "\n",
    "kneedle = KneeLocator(points[0], points[1], S=1.0, curve=\"convex\", direction=\"increasing\")\n",
    "knee = int( kneedle.knee )\n",
    "print(\"Meilleur paramètre epsilon  : \", round(points[1][knee], 3) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps = 1.478, min_samples=4)\n",
    "dbscan.fit(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_clusters = dbscan.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contingency table of species vs cluster labels\n",
    "crosstab = pds.crosstab(db_clusters,classes)\n",
    "sns.heatmap(crosstab, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster views in 2D projections\n",
    "\n",
    "db_results = df4.copy()\n",
    "db_results['cluster']= db_clusters\n",
    "classes_map = classes.map({'Africa':0, 'Asia':1, 'Europe':2, 'North America': 3, 'South America':4})\n",
    "db_results['class']= classes_map.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=db_results,hue='cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 Decision tree :\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import tree\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test, classes_train, classes_test = sklearn.model_selection.train_test_split(df4, df3.Continents,\n",
    "                                                             test_size=1/3, \n",
    "                                                             train_size=2/3,\n",
    "                                                             random_state=None, \n",
    "                                                             shuffle=True, \n",
    "                                                             stratify=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = tree.DecisionTreeClassifier(criterion='entropy')\n",
    "clf = clf.fit(df_train, classes_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_predicted = clf.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds.crosstab(classes_test, classes_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autre façon d'avoir la même table :\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(classes_test, classes_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score (classes_test, classes_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18,10))\n",
    "tree.plot_tree(clf,filled=True,class_names=clf.classes_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Autre visualisation plus sympa utilisant graphviz  (décommenter pour visualier):\n",
    "\n",
    "tree_plot = tree.export_graphviz(clf, out_file = None, \n",
    "                           feature_names = df_train.columns,\n",
    "                           class_names = clf.classes_, \n",
    "                           filled=True, rounded = True,\n",
    "                           special_characters = True)\n",
    "\n",
    "graph = graphviz.Source(tree_plot)\n",
    "#display ( graph ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Validation croisée :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold #cross-validation splitter\n",
    "from sklearn.model_selection import cross_validate #cross-validation evaluation of metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = ['accuracy', \n",
    "         'precision_macro', \n",
    "         'precision_weighted', \n",
    "         'recall_macro', \n",
    "         'recall_weighted', \n",
    "         'f1_macro', \n",
    "         'f1_weighted']\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, random_state=10, shuffle=True)\n",
    "cv_scores = cross_validate(clf, df4, classes, scoring = tests, cv = cv, return_train_score = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pds.DataFrame(cv_scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
