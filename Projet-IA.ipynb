{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy\n",
    "import math\n",
    "import sklearn\n",
    "import pandas as pds\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.cluster.hierarchy as sch\n",
    "#import sergio_peignier as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df = pds.read_csv(\"./datas/Data-IA-World-Development-Indicator.txt\", sep=\"\\t\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un peu de statistiques :\n",
    "sparse_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction qui supprime une colonne (attribut) si le nb de NaN >= limit\n",
    "\n",
    "def delete_NaN_col(df, limit):\n",
    "    NaN_col = df.isna().sum()\n",
    "    tmp = df.copy(deep=True) #temporary df\n",
    "    \n",
    "    for i in range(df.shape[1]):\n",
    "        if NaN_col[i] >= limit:\n",
    "            df = df.drop(columns = tmp.columns[i])\n",
    "            \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df2 = delete_NaN_col(sparse_df, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enlèvre les colonnes 'Time' et 'Time Code' qui ne nous interessent pas ici\n",
    "def remove_useless_col(df):\n",
    "    df = df.drop(columns = [\"Time\", \"Time Code\", \"Country Code\"])\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df2 = remove_useless_col(sparse_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df2.isna().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction qui supprime une ligne (object) si le nb de NaN >= limit\n",
    "\n",
    "def delete_NaN_row(df, limit):\n",
    "    NaN_row = df.isna().sum(axis=1)\n",
    "    tmp = df.copy(deep=True) #temporary df\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        if NaN_row[i] >= limit:\n",
    "            df = df.drop([i], axis = 0)\n",
    "            \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df3 = delete_NaN_row(sparse_df2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On remplace les indexes des ligne {0, 1, 2, ..n} par les noms de pays\n",
    "#Puis on supprime la colonne \"Countru Name\" pour n'avoir plus que des valeurs numériques\n",
    "sparse_df3.index = sparse_df3['Country Name']\n",
    "sparse_df3 = sparse_df3.drop(columns = ['Country Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Études des correlations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = sparse_df3.corr()\n",
    "corr_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représentation graphique des correlations\n",
    "plt.figure(figsize= (15, 12))\n",
    "sns.heatmap(corr_df,annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(corr_df,\n",
    "               figsize= (16, 12),\n",
    "               annot=True,\n",
    "               dendrogram_ratio=(0.1, 0.2),\n",
    "               row_cluster=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_corr(df, limit):\n",
    "    #On construit notre matrice de correlation en valeur absolue\n",
    "    corr_matrix = df.corr().abs()\n",
    "    \n",
    "    #Triangle supérieur de la matrice de corrélation : \n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > limit)]\n",
    "    df = df.drop(df[to_drop], axis=1)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = delete_corr(sparse_df3, 0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (15, 12))\n",
    "sns.heatmap(df.corr().abs(), annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On ne sait pas vraiment à quoi correspond cet attribut\n",
    "#De plus il faudrait normaliser ses valeurs, sauf que nous ne connaissons aucun référentiel pour faire cela\n",
    "df = df.drop(columns=[\"Net domestic credit (current LCU) [FM.AST.DOMS.CN]\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On renomme les labels des colonnes pour plus de fluidité\n",
    "df = df.rename(columns={\"Access to clean fuels and technologies for cooking (% of population) [EG.CFT.ACCS.ZS]\" : \"Clean fuels and technologies for cooking acces (% pop)\"})\n",
    "df = df.rename(columns={\"Aquaculture production (metric tons) [ER.FSH.AQUA.MT]\" : \"Aquaculture prod (metric tons)\"})\n",
    "df = df.rename(columns={\"Compulsory education, duration (years) [SE.COM.DURS]\" : \"Compulsory education duration (years)\"})\n",
    "df = df.rename(columns={\"Death rate, crude (per 1,000 people) [SP.DYN.CDRT.IN]\" : \"Death rate (per 10e3 )\"})\n",
    "df = df.rename(columns={\"Incidence of tuberculosis (per 10e5 people) [SH.TBS.INCD]\" : \"Incidence of tuberculosis (per 100 000)\"})\n",
    "df = df.rename(columns={\"Number of infant deaths [SH.DTH.IMRT]\" : \"Number of infant deaths\"})\n",
    "df = df.rename(columns={\"Preprimary education, duration (years) [SE.PRE.DURS]\" : \"Preprimary education duration (years)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisation relative :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_country(df, df_ref):\n",
    "    tmp = df.copy(deep = True)\n",
    "    for i, country in  enumerate( tmp[\"Country Name\"]):\n",
    "        if country not in df_ref.index.values:\n",
    "            df = df.drop(tmp.index[i], axis = 0)\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_size = pds.read_csv(\"./datas/Popula-schtroumpf/Population-size-per-country.txt\", sep=\"\\t\", header=0)\n",
    "population_size = remove_useless_col(population_size)\n",
    "population_size = delete_NaN_row(population_size, 1)\n",
    "population_size = remove_country(population_size, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surfaces = pds.read_csv(\"./datas/Surfa-schtroumpf/Country-surfaces.txt\", sep=\"\\t\", header=0)\n",
    "surfaces = remove_useless_col(surfaces)\n",
    "surfaces = delete_NaN_row(surfaces, 1)\n",
    "surfaces = remove_country(surfaces, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(population_size) == len(df), len(surfaces)== len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.copy(deep = True)\n",
    "print(\"Avant :\", \"\\n\")\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.iloc[:, 1] =  new_df.iloc[:, 1].values/surfaces.iloc[:, 1].values\n",
    "new_df.iloc[:, 5] =  new_df.iloc[:, 5].values/population_size.iloc[:, 1].values\n",
    "print(\"Après :\", \"\\n\")\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisation par centrage - réduction :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "    X = \\frac{X - \\mu}{\\sigma}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=new_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "sns.boxplot(data = new_df)\n",
    "plt.show()\n",
    "\n",
    "#On voit que les ordres de grandeur de nos données ainsi que leur variances ne sont pas du tout homogènes.\n",
    "#On va donc les normaliser (centrer - réduire) pour corriger ce défaut  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui centre et réduit une colonne de données pour les normaliser\n",
    "def normalizer (data):\n",
    "    # Quelques statistiques :\n",
    "    mean = np.mean(data)\n",
    "    var = np.var(data)\n",
    "    sd = math.sqrt(var)\n",
    "    \n",
    "    norm = []\n",
    "    for x in data:\n",
    "        norm.append((x-mean)/sd)\n",
    "    \n",
    "    return (norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_whole_df (df):\n",
    "    normed_df = df.copy(deep = True)\n",
    "    for i in df.columns:\n",
    "        normed_df[i] = normalizer(df[i])\n",
    "        \n",
    "    return (normed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_df = norm_whole_df(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,15))\n",
    "sns.boxplot(data = normed_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_outliers_row(df, limit):\n",
    "    z_scores = stats.zscore(normed_df) #calcule le z-score de df\n",
    "    abs_z_scores = np.abs(z_scores) # on passe en valeurs absolues\n",
    "    filtered_outliers = (abs_z_scores < limit).all(axis=1) # on ne garde que les lignes avec des valeurs > limit\n",
    "    new_df = df[filtered_outliers] #nouveau df\n",
    "    return (new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = search_outliers_row(normed_df, 2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,15))\n",
    "sns.boxplot(data = df2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pairplot après standardisation\n",
    "sns.pairplot(data=df2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création de classes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycountry_convert as pc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code = sparse_df[[\"Country Name\", \"Country Code\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code = remove_country(country_code, df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code_np = country_code[\"Country Code\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_to_continent(country_code):\n",
    "    res = []\n",
    "    for code3 in country_code :\n",
    "        code2 = pc.country_alpha3_to_country_alpha2(code3)\n",
    "        if (code2 == \"TL\"):\n",
    "            country_continent_code = \"AS\"\n",
    "        else:\n",
    "            country_continent_code = pc.country_alpha2_to_continent_code(code2)\n",
    "        country_continent_name = pc.convert_continent_code_to_continent_name(country_continent_code)\n",
    "        res.append(country_continent_name)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continents = country_to_continent(country_code_np)\n",
    "print(continents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_code[\"Continents\"] = continents\n",
    "country_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset clustering using K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utilisé le jeu de données fraichement filtré et normalisé df2 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un object KMeans :\n",
    "km = KMeans(n_clusters=4, init='k-means++',n_init=10, random_state=50, max_iter=300,).fit(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_clusters = km.labels_\n",
    "classes = country_code.Continents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On stocke les centroides obtenus :\n",
    "centroids = km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = km.predict(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using matplotlib.pyplot instead of seaborn.scatterplot to display the clusters.\n",
    "plt.scatter(df2[\"Clean fuels and technologies for cooking acces (% pop)\"], df2[\"Compulsory education duration (years)\"], c=clusters)\n",
    "plt.title('Data in Space', fontsize=14)\n",
    "plt.xlabel(\"Clean fuels and technologies for cooking acces (% pop)\",fontsize=14)\n",
    "plt.ylabel(\"Compulsory education duration (years)\",fontsize=14 )\n",
    "plt.scatter(centroids[:, 0], centroids[:, 2], c='red',s=150, alpha=0.4)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mesures sur nos kmeans :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "Counter(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SSE** :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSE=km.inertia_\n",
    "print(SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation du changement de nombre de cluster\n",
    "km = KMeans(n_clusters=3, init='k-means++',n_init=10, random_state=50, max_iter=300,).fit(df2)\n",
    "\n",
    "SSE=km.inertia_\n",
    "print(SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Courbe de la SSE en fonction du nombre de clusters\n",
    "SSE_liste=[]\n",
    "for i in range(2,10):\n",
    "    km2=KMeans(n_clusters=i, init='k-means++',  n_init=1, random_state=50, max_iter=1000).fit(df2)\n",
    "    SSE_liste.append(km2.inertia_)\n",
    "    \n",
    "#print(SSE_liste)\n",
    "\n",
    "SSE_liste_random=[]\n",
    "x=[]\n",
    "for i in range(2,10):\n",
    "    km3=KMeans(n_clusters=i, init='random',  n_init=1, random_state=50, max_iter=1000).fit(df2)\n",
    "    SSE_liste_random.append(km3.inertia_)\n",
    "    x.append(i)\n",
    "    \n",
    "#print(SSE_liste_random)\n",
    "\n",
    "plt.plot(x, SSE_liste,label=\"k-means++\")\n",
    "plt.plot(x, SSE_liste_random,label=\"Random\")\n",
    "plt.xlabel(\"Nombre de clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Table de contingence avec les différents clusters vs les classes (ici continents) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_crosstab = pds.crosstab(km_clusters,classes)\n",
    "sns.heatmap(km_crosstab, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesures externes : l'**entropie**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entropie des clusters (c) comparés aux différentes classes (j):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$-\\sum{p(j|c) \\times log(p(j|c)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$p(j|c)$ est la fréquence d'apparition de la classe j dans le cluster c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = km_crosstab.values/km_crosstab.values.sum(axis=1, keepdims=True) # divide each element of a row by the sum of the row\n",
    "entropy = [stats.entropy(row, base=2) for row in proba]\n",
    "print(\"entropy of each cluster: \", entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pureté** :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour calculer la pureté, chaque cluster est attribué à la classe qui est la plus fréquente dans ce cluster, puis la précision de cette attribution est mesurée en comptant le nombre d'éléments correctement attribués. Il s'agit donc de mesurer la précision d'un cluster à ne contenir les objets que d'une seule classe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En réalité il s'agit d'une terminologie dérivant de l'entropie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$purete = \\sum_{j=1}^{K} \\frac{m_c}{m} \\times purete(c)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $purete(c) = max(p(j,c))$;\n",
    "- $p(j,c)$ est la probabilité qu'un membre du cluster $c$ appartienne à la classe $j$;\n",
    "- $m_c$ est la taille du cluster $c$;\n",
    "- $m$ est la taille totale du nombre d'éléments (points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def purity_score(classes, predictions):\n",
    "    contingency_matrix = metrics.cluster.contingency_matrix(classes, predictions)\n",
    "    return ( np.sum(np.amax(contingency_matrix, axis=0)) / np.sum(contingency_matrix) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purity_score(classes, km_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ins>Remarque :</ins> Une grande pureté est facile à atteindre lorsque le nombre de clusters formés devient important. En particulier, la pureté tend vers $1$ si le nombre de cluster tend à être égale aux nombre de points. Ainsi, nous ne pouvons pas utiliser la pureté pour faire un compromis entre la qualité du regroupement et le nombre de regroupements.\n",
    "\n",
    "Une mesure qui nous permet de faire ce compromis est l'information mutuelle normalisée ou INM : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Information mutuel normalisée (IMN)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$IMN(j,c) = \\frac{2 \\times I(j, c)}{E(j) + E(c)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $j$ = label de la classe ;\n",
    "- $c$ = label du cluster ;\n",
    "- $E()$ = entropie ;\n",
    "- $I(j, c)$ = information mutuelle entre j et c. $I(j, c) = E(j) - E(j|c)$, où $E(j|c)$ désigne une entropie conditionnelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.normalized_mutual_info_score(classes, km_clusters, average_method='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesures Internes : le **coefficient de silhouette** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le coefficient de silhouette pour un  point correspond à la différence entre sa distance moyenne avec les points du même cluster que lui (**cohésion**) et la distance moyenne avec les points des autres clusters voisins (**séparation**). Il est compris en $-1$ et $1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Si on a une différence négative, le point est en moyenne plus proche du groupe voisin que du sien ;\n",
    " - Si on a une différence positive, le point est en moyenne plus proche de son groupe que du groupe voisin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Silh = metrics.silhouette_score(df2.values, \n",
    "                         km_clusters, \n",
    "                         metric='euclidean', \n",
    "                         sample_size=None) \n",
    "print(\"Coefficient de silhouette pour nos 3 clusters : \",Silh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yellowbrick.cluster import SilhouetteVisualizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avec le code suivant nous pouvons observer les silhouettes de chaque cluster, pour un nombre total de  2, 3, 4, 5, 6 et 7 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(3, 2, figsize=(15,10))\n",
    "for i in [2, 3, 4, 5, 6, 7]:\n",
    "    \n",
    "    km_simu = KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=100, random_state=42)\n",
    "    q, mod = divmod(i, 2) # permet d'attribuer les axes pour les subplots \n",
    "    \n",
    "    visualizer = SilhouetteVisualizer(km_simu, colors='yellowbrick', ax=ax[q-1][mod])\n",
    "    visualizer.fit(df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierachical clustering :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthode : \"complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_complete = sch.linkage(df2, method = 'complete', metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 40))\n",
    "dendro = sch.dendrogram(z_complete, \n",
    "                        orientation='right', \n",
    "                        leaf_rotation=0, \n",
    "                        leaf_font_size=14,\n",
    "                        labels = df2.index)\n",
    "plt.title(\"Dendrogram\")\n",
    "plt.ylabel(\"Countries\")\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Méthode : \"single\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_single = sch.linkage(df2, method = 'single', metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_single.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 40))\n",
    "dendro = sch.dendrogram(z_single, \n",
    "                        orientation='right', \n",
    "                        leaf_rotation=0, \n",
    "                        leaf_font_size=14,\n",
    "                        labels = df2.index)\n",
    "plt.title(\"Dendrogram\")\n",
    "plt.ylabel(\"Countries\")\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2nd derivative of the distances\n",
    "\n",
    "acceleration_complete = np.diff(z_complete[:,2], 2)\n",
    "acceleration_single = np.diff(z_single[:,2], 2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 10))\n",
    "\n",
    "plt.subplot(131)\n",
    "plt.plot(z_single[:, 2], 'o-', color = \"blue\")\n",
    "plt.plot(z_complete[:, 2], 'o-', color = \"orange\")\n",
    "plt.legend([\"single\",\"complete\"])\n",
    "plt.ylabel(\"Hauteur\")\n",
    "plt.xlabel(\"Pays par ordre croissant\")\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.plot(z_complete[:, 2], 'o-', color = \"orange\")\n",
    "plt.plot(acceleration_complete, 'o-', color='green')\n",
    "plt.ylabel(\"Hauteur\")\n",
    "plt.legend([\"complete\",\"dérivée seconde de complete\"])\n",
    "plt.xlabel(\"Pays par ordre croissant\")\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.plot(z_single[:, 2], 'o-', color = \"blue\")\n",
    "plt.plot(acceleration_complete, 'o-', color='green')\n",
    "plt.legend([\"single\",\"dérivée seconde de signle\"])\n",
    "plt.ylabel(\"Hauteur\")\n",
    "plt.xlabel(\"Pays par ordre croissant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DB scan :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=2)\n",
    "dbscan.fit(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = dbscan.labels_\n",
    "classes = country_code.Continents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contingency table of species vs cluster labels\n",
    "crosstab = pds.crosstab(clusters,classes)\n",
    "sns.heatmap(crosstab, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster views in 2D projections\n",
    "\n",
    "db_results = df2.copy()\n",
    "db_results['cluster']= clusters\n",
    "classes_map = classes.map({'Africa':0, 'Asia':1, 'Europe':2, 'North America': 3, 'South America':4})\n",
    "db_results['class']= classes_map.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=db_results,hue='cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
