{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy\n",
    "import math\n",
    "import sklearn\n",
    "import pandas as pds\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.cluster.hierarchy as sch\n",
    "#import sergio_peignier as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df = pds.read_csv(\"./datas/Data-IA-World-Development-Indicator.txt\", sep=\"\\t\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un peu de statistiques :\n",
    "sparse_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction qui supprime une colonne (attribut) si le nb de NaN >= limit\n",
    "\n",
    "def delete_NaN_col(df, limit):\n",
    "    NaN_col = df.isna().sum()\n",
    "    tmp = df.copy(deep=True) #temporary df\n",
    "    \n",
    "    for i in range(df.shape[1]):\n",
    "        if NaN_col[i] >= limit:\n",
    "            df = df.drop(columns = tmp.columns[i])\n",
    "            \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df2 = delete_NaN_col(sparse_df, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enlèvre les colonnes 'Time' et 'Time Code' qui ne nous interessent pas ici\n",
    "def remove_useless_col(df):\n",
    "    df = df.drop(columns = [\"Time\", \"Time Code\", \"Country Code\"])\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df2 = remove_useless_col(sparse_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df2.isna().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction qui supprime une ligne (object) si le nb de NaN >= limit\n",
    "\n",
    "def delete_NaN_row(df, limit):\n",
    "    NaN_row = df.isna().sum(axis=1)\n",
    "    tmp = df.copy(deep=True) #temporary df\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        if NaN_row[i] >= limit:\n",
    "            df = df.drop([i], axis = 0)\n",
    "            \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df3 = delete_NaN_row(sparse_df2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On remplace les indexes des ligne {0, 1, 2, ..n} par les noms de pays\n",
    "#Puis on supprime la colonne \"Countru Name\" pour n'avoir plus que des valeurs numériques\n",
    "sparse_df3.index = sparse_df3['Country Name']\n",
    "sparse_df3 = sparse_df3.drop(columns = ['Country Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Études des correlations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = sparse_df3.corr()\n",
    "corr_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représentation graphique des correlations\n",
    "plt.figure(figsize= (15, 12))\n",
    "sns.heatmap(corr_df,annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(corr_df,\n",
    "               figsize= (16, 12),\n",
    "               annot=True,\n",
    "               dendrogram_ratio=(0.1, 0.2),\n",
    "               row_cluster=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_corr(df, limit):\n",
    "    #On construit notre matrice de correlation en valeur absolue\n",
    "    corr_matrix = df.corr().abs()\n",
    "    \n",
    "    #Triangle supérieur de la matrice de corrélation : \n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > limit)]\n",
    "    df = df.drop(df[to_drop], axis=1)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = delete_corr(sparse_df3, 0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (15, 12))\n",
    "sns.heatmap(df.corr().abs(), annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#On ne sait pas vraiment à quoi correspond cet attribut\n",
    "#De plus il faudrait normaliser ses valeurs, sauf que nous ne connaissons aucun référentiel pour faire cela\n",
    "df = df.drop(columns=[\"Net domestic credit (current LCU) [FM.AST.DOMS.CN]\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On renomme les labels des colonnes pour plus de fluidité\n",
    "df = df.rename(columns={\"Access to clean fuels and technologies for cooking (% of population) [EG.CFT.ACCS.ZS]\" : \"Clean fuels and technologies for cooking acces (% pop)\"})\n",
    "df = df.rename(columns={\"Aquaculture production (metric tons) [ER.FSH.AQUA.MT]\" : \"Aquaculture prod (metric tons)\"})\n",
    "df = df.rename(columns={\"Compulsory education, duration (years) [SE.COM.DURS]\" : \"Compulsory education duration (years)\"})\n",
    "df = df.rename(columns={\"Death rate, crude (per 1,000 people) [SP.DYN.CDRT.IN]\" : \"Death rate (per 10e3 )\"})\n",
    "df = df.rename(columns={\"Incidence of tuberculosis (per 10e5 people) [SH.TBS.INCD]\" : \"Incidence of tuberculosis (per 100 000)\"})\n",
    "df = df.rename(columns={\"Number of infant deaths [SH.DTH.IMRT]\" : \"Number of infant deaths\"})\n",
    "df = df.rename(columns={\"Preprimary education, duration (years) [SE.PRE.DURS]\" : \"Preprimary education duration (years)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisation relative :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_country(df, df_ref):\n",
    "    tmp = df.copy(deep = True)\n",
    "    for i, country in  enumerate( tmp[\"Country Name\"]):\n",
    "        if country not in df_ref.index.values:\n",
    "            df = df.drop(tmp.index[i], axis = 0)\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_size = pds.read_csv(\"./datas/Popula-schtroumpf/Population-size-per-country.txt\", sep=\"\\t\", header=0)\n",
    "population_size = remove_useless_col(population_size)\n",
    "population_size = delete_NaN_row(population_size, 1)\n",
    "population_size = remove_country(population_size, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "surfaces = pds.read_csv(\"./datas/Surfa-schtroumpf/Country-surfaces.txt\", sep=\"\\t\", header=0)\n",
    "surfaces = remove_useless_col(surfaces)\n",
    "surfaces = delete_NaN_row(surfaces, 1)\n",
    "surfaces = remove_country(surfaces, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (len(population_size) == len(df), len(surfaces)== len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.copy(deep = True)\n",
    "print(\"Avant :\", \"\\n\")\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.iloc[:, 1] =  new_df.iloc[:, 1].values/surfaces.iloc[:, 1].values\n",
    "new_df.iloc[:, 5] =  new_df.iloc[:, 5].values/population_size.iloc[:, 1].values\n",
    "print(\"Après :\", \"\\n\")\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisation par centrage - réduction :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "    X = \\frac{X - \\mu}{\\sigma}\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=new_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "sns.boxplot(data = new_df)\n",
    "plt.show()\n",
    "\n",
    "#On voit que les ordres de grandeur de nos données ainsi que leur variances ne sont pas du tout homogènes.\n",
    "#On va donc les normaliser (centrer - réduire) pour corriger ce défaut  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui centre et réduit une colonne de données pour les normaliser\n",
    "def normalizer (data):\n",
    "    # Quelques statistiques :\n",
    "    mean = np.mean(data)\n",
    "    var = np.var(data)\n",
    "    sd = math.sqrt(var)\n",
    "    \n",
    "    norm = []\n",
    "    for x in data:\n",
    "        norm.append((x-mean)/sd)\n",
    "    \n",
    "    return (norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_whole_df (df):\n",
    "    normed_df = df.copy(deep = True)\n",
    "    for i in df.columns:\n",
    "        normed_df[i] = normalizer(df[i])\n",
    "        \n",
    "    return (normed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_df = norm_whole_df(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,15))\n",
    "sns.boxplot(data = normed_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_outliers_row(df, limit):\n",
    "    z_scores = stats.zscore(normed_df) #calcule le z-score de df\n",
    "    abs_z_scores = np.abs(z_scores) # on passe en valeurs absolues\n",
    "    filtered_outliers = (abs_z_scores < limit).all(axis=1) # on ne garde que les lignes avec des valeurs > limit\n",
    "    new_df = df[filtered_outliers] #nouveau df\n",
    "    return (new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = search_outliers_row(normed_df, 2.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,15))\n",
    "sns.boxplot(data = df2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pairplot après standardisation\n",
    "sns.pairplot(data=df2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset clustering using K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un object KMeans :\n",
    "km = KMeans(n_clusters=4, init='k-means++',n_init=10, random_state=50, max_iter=300,).fit(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On stocke les centroides obtenus :\n",
    "centroids=km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = km.predict(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter \n",
    "Counter(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSE=km.inertia_\n",
    "print(SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using matplotlib.pyplot instead of seaborn.scatterplot to display the clusters.\n",
    "plt.scatter(df2[\"Clean fuels and technologies for cooking acces (% pop)\"], df2[\"Compulsory education duration (years)\"], c=clusters)\n",
    "plt.title('Data in Space', fontsize=14)\n",
    "plt.xlabel(\"Clean fuels and technologies for cooking acces (% pop)\",fontsize=14)\n",
    "plt.ylabel(\"Compulsory education duration (years)\",fontsize=14 )\n",
    "plt.scatter(centroids[:, 0], centroids[:, 2], c='red',s=150, alpha=0.4)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation du changement de nombre de cluster\n",
    "km = KMeans(n_clusters=3, init='k-means++',n_init=10, random_state=50, max_iter=300,).fit(df2)\n",
    "\n",
    "SSE=km.inertia_\n",
    "print(SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Courbe de la SSE en fonction du nombre de clusters\n",
    "SSE_liste=[]\n",
    "for i in range(2,10):\n",
    "    km2=KMeans(n_clusters=i, init='k-means++',  n_init=1, random_state=50, max_iter=1000).fit(df2)\n",
    "    SSE_liste.append(km2.inertia_)\n",
    "    \n",
    "#print(SSE_liste)\n",
    "\n",
    "SSE_liste_random=[]\n",
    "x=[]\n",
    "for i in range(2,10):\n",
    "    km3=KMeans(n_clusters=i, init='random',  n_init=1, random_state=50, max_iter=1000).fit(df2)\n",
    "    SSE_liste_random.append(km3.inertia_)\n",
    "    x.append(i)\n",
    "    \n",
    "#print(SSE_liste_random)\n",
    "\n",
    "plt.plot(x, SSE_liste,label=\"k-means++\")\n",
    "plt.plot(x, SSE_liste_random,label=\"Random\")\n",
    "plt.xlabel(\"Nombre de clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierachical clustering :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = sch.linkage(df2, method = 'complete', metric='euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 40))\n",
    "dendro = sch.dendrogram(z, \n",
    "                        orientation='right', \n",
    "                        leaf_rotation=0, \n",
    "                        leaf_font_size=14)\n",
    "plt.title(\"Dendrogram\")\n",
    "plt.ylabel(\"Countries\")\n",
    "plt.xlabel(\"Distance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(z[:, 2], 'o-')\n",
    "plt.grid(axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
