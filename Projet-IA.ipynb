{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy\n",
    "import math\n",
    "import sklearn\n",
    "import pandas as pds\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import sergio_peignier as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df = pds.read_csv(\"./datas/Data-IA-World-Development-Indicator.txt\", sep=\"\\t\", header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Un peu de statistiques :\n",
    "sparse_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction qui supprime une colonne (attribut) si le nb de NaN >= limit\n",
    "\n",
    "def delete_NaN_col(df, limit):\n",
    "    NaN_col = df.isna().sum()\n",
    "    tmp = df.copy(deep=True) #temporary df\n",
    "    \n",
    "    for i in range(df.shape[1]):\n",
    "        if NaN_col[i] >= limit:\n",
    "            df = df.drop(columns = tmp.columns[i])\n",
    "            \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df2 = delete_NaN_col(sparse_df, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enlèvre les colonnes 'Time' et 'Time Code' qui ne nous interessent pas ici\n",
    "sparse_df2 = sparse_df2.drop(columns = ['Time', 'Time Code', 'Country Code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df2.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df2.isna().sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction qui supprime une ligne (object) si le nb de NaN >= limit\n",
    "\n",
    "def delete_NaN_row(df, limit):\n",
    "    NaN_row = df.isna().sum(axis=1)\n",
    "    tmp = df.copy(deep=True) #temporary df\n",
    "    \n",
    "    for i in range(df.shape[0]):\n",
    "        if NaN_row[i] >= limit:\n",
    "            df = df.drop([i], axis = 0)\n",
    "            \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df3 = delete_NaN_row(sparse_df2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nous allons maintenant stocker les noms de pays dans la variable country_labels\n",
    "# En effet, nous pourrons supprimer la colonne \"Country Name\" et n'avoir plus que des valeurs numériques.\n",
    "# Les noms des pays seront toujours stockés dans cette variable et nous pourrons y faire référence dès que nécessaire\n",
    "\n",
    "country_labels = sparse_df3.loc[:][\"Country Name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On enlèvre la colonnes 'Country Name' \n",
    "sparse_df3 = sparse_df3.drop(columns = ['Country Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = sparse_df3.corr()\n",
    "corr_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Représentation graphique des correlations\n",
    "plt.figure(figsize= (15, 12))\n",
    "sns.heatmap(corr_df,annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.clustermap(corr_df,\n",
    "               figsize= (16, 12),\n",
    "               annot=True,\n",
    "               dendrogram_ratio=(0.1, 0.2),\n",
    "               row_cluster=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_corr(df, limit):\n",
    "    #On construit notre matrice de correlation en valeur absolue\n",
    "    corr_matrix = df.corr().abs()\n",
    "    \n",
    "    #Triangle supérieur de la matrice de corrélation : \n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > limit)]\n",
    "    df = df.drop(df[to_drop], axis=1)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = delete_corr(sparse_df3, 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize= (15, 12))\n",
    "sns.heatmap(df.corr().abs(), annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = country_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Net domestic credit (current LCU) [FM.AST.DOMS.CN]\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,12))\n",
    "sns.boxplot(data = df)\n",
    "plt.show()\n",
    "\n",
    "#On voit que les ordres de grandeur de nos données ainsi que leur variances ne sont pas du tout homogènes.\n",
    "#On va donc les normaliser (centrer - réduire) pour corriger ce défaut  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction qui centre et réduit une colonne de données pour les normaliser\n",
    "def normalizer (data):\n",
    "    # Quelques statistiques :\n",
    "    mean = np.mean(data)\n",
    "    var = np.var(data)\n",
    "    sd = math.sqrt(var)\n",
    "    \n",
    "    norm = []\n",
    "    for x in data:\n",
    "        norm.append((x-mean)/sd)\n",
    "    \n",
    "    return (norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_whole_df (df):\n",
    "    normed_df = df.copy(deep = True)\n",
    "    for i in df.columns:\n",
    "        normed_df[i] = normalizer(df[i])\n",
    "        \n",
    "    return (normed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_df = norm_whole_df(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,15))\n",
    "sns.boxplot(data = normed_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_outliers_row(df):\n",
    "    tmp = df.copy(deep = True)\n",
    "    for i in range (tmp.shape[0]):\n",
    "        for j in range (tmp.shape[1]):\n",
    "            if (tmp.iloc[i, j] > 3):\n",
    "                df = df.drop(tmp.index[i])\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = search_outliers_row(normed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,15))\n",
    "sns.boxplot(data = df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pairplot après standardisation\n",
    "sns.pairplot(data=df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset clustering using K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'un object KMeans :\n",
    "km = KMeans(n_clusters=6, init='k-means++',n_init=10, random_state=50, max_iter=300,).fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = km.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On stocke les centroides obtenus :\n",
    "centroids=km.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = km.predict(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SSE=km.inertia_\n",
    "print(SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using matplotlib.pyplot instead of seaborn.scatterplot to display the clusters.\n",
    "plt.scatter(df[\"Death rate, crude (per 1,000 people) [SP.DYN.CDRT.IN]\"], df[\"Aquaculture production (metric tons) [ER.FSH.AQUA.MT]\"], c=clusters)\n",
    "plt.title('Data in Space', fontsize=14)\n",
    "plt.xlabel(\"Death rate, crude (per 1,000 people) [SP.DYN.CDRT.IN]\",fontsize=14)\n",
    "plt.ylabel(\"Aquaculture production (metric tons) [ER.FSH.AQUA.MT]\",fontsize=14 )\n",
    "plt.scatter(centroids[:, 3], centroids[:, 1], c='red',s=150, alpha=0.4)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using matplotlib.pyplot instead of seaborn.scatterplot to display the clusters.\n",
    "plt.scatter(df[\"Access to clean fuels and technologies for cooking (% of population) [EG.CFT.ACCS.ZS]\"], df[\"Aquaculture production (metric tons) [ER.FSH.AQUA.MT]\"], c=clusters)\n",
    "plt.title('Data in Space', fontsize=14)\n",
    "plt.xlabel(\"Access to clean fuels and technologies for cooking (% of population) [EG.CFT.ACCS.ZS]\",fontsize=14)\n",
    "plt.ylabel(\"Aquaculture production (metric tons) [ER.FSH.AQUA.MT]\",fontsize=14 )\n",
    "plt.scatter(centroids[:, 0], centroids[:, 2], c='red',s=150, alpha=0.4)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation du changement de nombre de cluster\n",
    "km = KMeans(n_clusters=3, init='k-means++',n_init=10, random_state=50, max_iter=300,).fit(df)\n",
    "\n",
    "SSE=km.inertia_\n",
    "print(SSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Courbe de la SSE en fonction du nombre de clusters\n",
    "SSE_liste=[]\n",
    "for i in range(2,10):\n",
    "    km2=KMeans(n_clusters=i, init='k-means++',  n_init=1, random_state=50, max_iter=1000).fit(df)\n",
    "    SSE_liste.append(km2.inertia_)\n",
    "#print(SSE_liste)\n",
    "\n",
    "SSE_liste_random=[]\n",
    "x=[]\n",
    "for i in range(2,10):\n",
    "    km3=KMeans(n_clusters=i, init='random',  n_init=1, random_state=50, max_iter=1000).fit(df)\n",
    "    SSE_liste_random.append(km3.inertia_)\n",
    "    x.append(i)\n",
    "#print(SSE_liste_random)\n",
    "\n",
    "plt.plot(x, SSE_liste,label=\"k-means++\")\n",
    "plt.plot(x, SSE_liste_random,label=\"Random\")\n",
    "plt.xlabel(\"Nombre de clusters\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
